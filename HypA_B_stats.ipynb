{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = \"../new-results/\"\n",
    "hyp_A_path = base_path + \"hypothA/\"\n",
    "hyp_B_path = base_path + \"hypothB/\"\n",
    "hyp_0_nice_path = base_path + \"hypoth_0/Nice/\"\n",
    "hyp_0_hate_path = base_path + \"hypoth_0/Hate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nice_subreddits = [\"TheGirlSurvivalGuide\", \"ForeverAlone\", \"TwoXChromosomes\", \"depression\", \"Anxiety\", \"CasualConversation\", \"RandomKindness\", \"fountainpens\", \"knitting\", \"Buddhism\", \"ABraThatFits\", \"loseit\", \"history\"]\n",
    "hate_subreddits = [\"Physical_Removal\",\"dankmemes\",\"PussyPass\", \"MensRights\", \"europeannationalism\", \"NationalSocialism\", \"WeissSturm\", \"Physical_Removal\", \"DebateAltRight\", \"WhiteRights\", \"TheDonald\", \"uncensorednews\", \"sjwhate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 0\n",
    "\n",
    "Let's look at how many times we get something significant, and also how many values we keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE SET:  ../new-results/hypoth_0/Nice/\n",
      "ABraThatFits ppron 559\n",
      "ABraThatFits article 559\n",
      "ABraThatFits conj 559\n",
      "loseit pronoun 2609\n",
      "loseit ppron 881\n",
      "loseit prep 1423\n",
      "loseit Dic 2609\n",
      "ForeverAlone pronoun 2254\n",
      "Buddhism pronoun 1310\n",
      "Buddhism ppron 715\n",
      "Buddhism article 1310\n",
      "Buddhism prep 1091\n",
      "TwoXChromosomes pronoun 3878\n",
      "TwoXChromosomes ipron 2817\n",
      "TwoXChromosomes prep 1604\n",
      "TwoXChromosomes Dic 4043\n",
      "CasualConversation ppron 620\n",
      "CasualConversation Dic 2740\n",
      "depression pronoun 673\n",
      "depression ppron 673\n",
      "depression Dic 673\n",
      "history Dic 590\n",
      "SpearmanrResult(correlation=-0.3250296152947949, pvalue=0.13995621497670302) 22\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "FILE SET:  ../new-results/hypoth_0/Hate/\n",
      "DebateAltRight pronoun 2661\n",
      "DebateAltRight ipron 604\n",
      "DebateAltRight prep 707\n",
      "The_Donald Dic 913\n",
      "MensRights pronoun 864\n",
      "MensRights ppron 798\n",
      "MensRights prep 937\n",
      "MensRights Dic 937\n",
      "SpearmanrResult(correlation=0.16766767666785626, pvalue=0.69146535164673595) 8\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "can_retain = []\n",
    "for file_set in [hyp_0_nice_path, hyp_0_hate_path]:\n",
    "    print \"FILE SET: \", file_set\n",
    "    files = os.listdir(file_set)\n",
    "    test_corr = []\n",
    "    for fName in files:\n",
    "        if \".csv\" not in fName:\n",
    "            continue\n",
    "        itm = fName.split(\"_\")\n",
    "        subreddit = itm[0]\n",
    "        feature = itm[1]\n",
    "\n",
    "        with open(file_set+fName, \"r\") as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            reader.next()\n",
    "            for line in reader:\n",
    "                subreddit = line[0]\n",
    "                feature = line[1]\n",
    "                accomm = float(line[2])\n",
    "                p_value = float(line[4])\n",
    "                retained = int(line[5]) - int(line[6])\n",
    "        \n",
    "                if p_value < 0.05 and retained > 500:\n",
    "                    print subreddit, feature, retained   \n",
    "                    test_corr.append([p_value, retained])\n",
    "                    can_retain.append((subreddit, feature))\n",
    "                \n",
    "    #test to see if number retained correlated with accomm value     \n",
    "    X = zip(*test_corr)[0]\n",
    "    Y = zip(*test_corr)[1]\n",
    "    print spearmanr(X, Y), len(X)\n",
    "    print \"\\n \\n \\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis A\n",
    "\n",
    "The amount of accommodation towards a user by users in general is not correlated with historical upvotes. \n",
    "\n",
    "Here we only use those occassions where we found that accommodation did exist, AND we retained enough user pairs per subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(hyp_A_path)\n",
    "nice_feature_dict = {}\n",
    "hate_feature_dict = {}\n",
    "\n",
    "for fName in files:\n",
    "    itm = fName.split(\"_\")\n",
    "    subreddit = itm[0]\n",
    "    feature = itm[1]\n",
    "    \n",
    "    with open(hyp_A_path+fName, \"rb\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        reader.next()\n",
    "        values = list(reader)\n",
    "        \n",
    "    if subreddit in nice_subreddits:\n",
    "        if (subreddit, feature) in can_retain:\n",
    "            if feature not in nice_feature_dict:\n",
    "                nice_feature_dict[feature] = []\n",
    "            nice_feature_dict[feature].extend(values)\n",
    "        \n",
    "    elif subreddit in hate_subreddits:\n",
    "        if (subreddit, feature) in can_retain:\n",
    "            if feature not in hate_feature_dict:\n",
    "                hate_feature_dict[feature] = []\n",
    "            hate_feature_dict[feature].extend(values)\n",
    "        \n",
    "    else:\n",
    "        print subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppron SpearmanrResult(correlation=-0.019943564307792875, pvalue=0.62299628779880445) 610\n",
      "differ SpearmanrResult(correlation=0.085931920708998535, pvalue=0.24611377864606962) 184\n",
      "pronoun SpearmanrResult(correlation=-0.0059434308263881675, pvalue=0.84285736768067787) 1115\n",
      "ipron SpearmanrResult(correlation=-0.074218815052095655, pvalue=0.13889721775875422) 399\n",
      "Dic SpearmanrResult(correlation=0.0036764447294804488, pvalue=0.94033404130571707) 417\n",
      "article SpearmanrResult(correlation=0.045410712540260537, pvalue=0.55770049042956149) 169\n",
      "conj SpearmanrResult(correlation=0.045776229889798174, pvalue=0.55453093975365153) 169\n",
      "prep SpearmanrResult(correlation=-0.059851015123887713, pvalue=0.11920979207336999) 679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Caitrin/anaconda/lib/python2.7/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "for feature in hate_feature_dict:\n",
    "    X = zip(*hate_feature_dict[feature])[0]\n",
    "    Y = zip(*hate_feature_dict[feature])[1]\n",
    "    print feature, spearmanr(X, Y), len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppron SpearmanrResult(correlation=0.026146965145572954, pvalue=0.25463455190300244) 1900\n",
      "pronoun SpearmanrResult(correlation=-0.032980465250315727, pvalue=0.028370641869235106) 4418\n",
      "ipron SpearmanrResult(correlation=0.024244255241664948, pvalue=0.27609684825028663) 2020\n",
      "Dic SpearmanrResult(correlation=-0.018112371062585658, pvalue=0.18976128913686305) 5243\n",
      "article SpearmanrResult(correlation=0.078095741021916951, pvalue=0.088761320922540021) 476\n",
      "conj SpearmanrResult(correlation=0.074662977427487079, pvalue=0.18626347998036952) 315\n",
      "prep SpearmanrResult(correlation=-0.0025055022011575595, pvalue=0.90155324301987205) 2440\n"
     ]
    }
   ],
   "source": [
    "for feature in nice_feature_dict:\n",
    "    X = zip(*nice_feature_dict[feature])[0]\n",
    "    Y = zip(*nice_feature_dict[feature])[1]\n",
    "    \n",
    "    print feature, spearmanr(X, Y), len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis B\n",
    "\n",
    "The amount of accommodation between user pairs is not correlated to the pairsâ€™ prior interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(hyp_B_path)\n",
    "nice_feature_dict = {}\n",
    "hate_feature_dict = {}\n",
    "\n",
    "for fName in files:\n",
    "    if \"Physical_Removal\" in fName:\n",
    "        itm = fName.split(\"_\")\n",
    "        subreddit = \"Physical_Removal\" \n",
    "        feature = itm[2]\n",
    "    else:\n",
    "        itm = fName.split(\"_\")\n",
    "        subreddit = itm[0]\n",
    "        feature = itm[1]\n",
    "    values = []\n",
    "    with open(hyp_B_path+fName, \"rb\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        reader.next()\n",
    "        for line in reader:\n",
    "            values.append(line[2:])\n",
    "        \n",
    "    if subreddit in nice_subreddits:\n",
    "        if feature not in nice_feature_dict:\n",
    "            nice_feature_dict[feature] = []\n",
    "        nice_feature_dict[feature].extend(values)\n",
    "        \n",
    "    elif subreddit in hate_subreddits:\n",
    "        if feature not in hate_feature_dict:\n",
    "            hate_feature_dict[feature] = []\n",
    "        hate_feature_dict[feature].extend(values)\n",
    "        \n",
    "    else:\n",
    "        print subreddit\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppron SpearmanrResult(correlation=-0.059045779835806445, pvalue=0.0078360828028494357) 2027\n",
      "differ SpearmanrResult(correlation=0.042910844929661039, pvalue=0.24852159457285103) 725\n",
      "tentat SpearmanrResult(correlation=0.05685771898341959, pvalue=0.2175802018823737) 472\n",
      "pronoun SpearmanrResult(correlation=0.022101590886812853, pvalue=0.11803200669905906) 5003\n",
      "i SpearmanrResult(correlation=-0.026858089173722448, pvalue=0.74091320460888488) 154\n",
      "certain SpearmanrResult(correlation=0.10350312902653395, pvalue=0.19850832462886159) 156\n",
      "discrep SpearmanrResult(correlation=0.060835872627910063, pvalue=0.49513798529782616) 128\n",
      "we SpearmanrResult(correlation=-0.11627053425637858, pvalue=0.54808187246842932) 29\n",
      "you SpearmanrResult(correlation=0.038892431789130016, pvalue=0.57333447537731375) 212\n",
      "quant SpearmanrResult(correlation=-0.010918542177352423, pvalue=0.82959940413866007) 391\n",
      "they SpearmanrResult(correlation=-0.093656097368635477, pvalue=0.45447557843948994) 66\n",
      "ipron SpearmanrResult(correlation=0.033833240228116269, pvalue=0.25919531503957199) 1114\n",
      "negate SpearmanrResult(correlation=0.079845363393128213, pvalue=0.42971642421557876) 100\n",
      "article SpearmanrResult(correlation=-0.013509797742014563, pvalue=0.7071028382739476) 776\n",
      "conj SpearmanrResult(correlation=0.029393045908909923, pvalue=0.39942960508646519) 824\n",
      "Dic SpearmanrResult(correlation=0.0056754068518078049, pvalue=0.60008313088423115) 8536\n",
      "prep SpearmanrResult(correlation=0.019224735480615537, pvalue=0.35208572390786896) 2345\n",
      "shehe SpearmanrResult(correlation=-0.31535427482960188, pvalue=0.23414268702674451) 16\n"
     ]
    }
   ],
   "source": [
    "for feature in hate_feature_dict:\n",
    "    X = zip(*hate_feature_dict[feature])[0]\n",
    "    Y = zip(*hate_feature_dict[feature])[1]\n",
    "    print feature, spearmanr(X, Y), len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppron SpearmanrResult(correlation=-0.03060893386244436, pvalue=0.034728258414860276) 4759\n",
      "differ SpearmanrResult(correlation=0.059973736875852099, pvalue=0.081626962573456446) 844\n",
      "tentat SpearmanrResult(correlation=-0.0020734303251507494, pvalue=0.94887010177534448) 959\n",
      "pronoun SpearmanrResult(correlation=0.011413635694116988, pvalue=0.17697956873224946) 13994\n",
      "i SpearmanrResult(correlation=-0.056199246082839632, pvalue=0.10015419494279018) 857\n",
      "certain SpearmanrResult(correlation=-0.07823070042675867, pvalue=0.2511693607478267) 217\n",
      "discrep SpearmanrResult(correlation=0.034641472104831705, pvalue=0.51175834594447855) 361\n",
      "we SpearmanrResult(correlation=0.21962409342573727, pvalue=0.41376534557879097) 16\n",
      "Dic SpearmanrResult(correlation=0.0095675370769240722, pvalue=0.20894995142952152) 17248\n",
      "quant SpearmanrResult(correlation=-0.019624571883851527, pvalue=0.71922749743190473) 338\n",
      "shehe SpearmanrResult(correlation=-0.10154882897828892, pvalue=0.65294926514858864) 22\n",
      "they SpearmanrResult(correlation=-0.065773165089480223, pvalue=0.56723093705293204) 78\n",
      "ipron SpearmanrResult(correlation=0.00070630811892460031, pvalue=0.96002238334463919) 5039\n",
      "negate SpearmanrResult(correlation=-0.022806369092471374, pvalue=0.76783867135641704) 170\n",
      "article SpearmanrResult(correlation=-0.0086403477655887274, pvalue=0.64145421447521456) 2907\n",
      "you SpearmanrResult(correlation=-0.076242760329780349, pvalue=0.11398202828171851) 431\n",
      "prep SpearmanrResult(correlation=0.0091515623472940618, pvalue=0.46111349380543554) 6488\n",
      "conj SpearmanrResult(correlation=-0.0053733841362111016, pvalue=0.82979031569343098) 1603\n"
     ]
    }
   ],
   "source": [
    "for feature in nice_feature_dict:\n",
    "    X = zip(*nice_feature_dict[feature])[0]\n",
    "    Y = zip(*nice_feature_dict[feature])[1]\n",
    "    \n",
    "    print feature, spearmanr(X, Y), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
